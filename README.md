# CodeCrusaders
Using Local LLMs to Support Software Development and Test

Planned Features:
- Right sidebar with secondary functions
	- Adding new models (done but not moved)
   	- Deleting models
   	- Search for new models
- Left sidebar with chat histories
- Allow user to read model information from within app
  	- Must somehow read info from ollama's website
- Auto generated metrics and visuals
  	- Model step timer is done already
  	- Time per token
  	- Time to first token
  	- CPU usage
  	- etc.
  		- Create tables, graphs, and/or other viusals for easy analysis
- Create a way to compare two or more models by running them side by side with the same prompt

Installation Guide (Will be turned into full document at a later date):
- run 'python3 code_crusaders.py' to check for/install dependencies and run ui
